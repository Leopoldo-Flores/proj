[2024-05-01T18:49:19.849+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: homework2_data_pipeline_demo.data_acquisition manual__2024-04-30T20:55:51.830154+00:00 [queued]>
[2024-05-01T18:49:19.860+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: homework2_data_pipeline_demo.data_acquisition manual__2024-04-30T20:55:51.830154+00:00 [queued]>
[2024-05-01T18:49:19.862+0000] {taskinstance.py:2193} INFO - Starting attempt 17 of 17
[2024-05-01T18:49:19.880+0000] {taskinstance.py:2217} INFO - Executing <Task(_PythonVirtualenvDecoratedOperator): data_acquisition> on 2024-04-30 20:55:51.830154+00:00
[2024-05-01T18:49:19.886+0000] {standard_task_runner.py:60} INFO - Started process 10193 to run task
[2024-05-01T18:49:19.891+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'homework2_data_pipeline_demo', 'data_acquisition', 'manual__2024-04-30T20:55:51.830154+00:00', '--job-id', '136', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmp4hmtvadx']
[2024-05-01T18:49:19.892+0000] {standard_task_runner.py:88} INFO - Job 136: Subtask data_acquisition
[2024-05-01T18:49:19.961+0000] {task_command.py:423} INFO - Running <TaskInstance: homework2_data_pipeline_demo.data_acquisition manual__2024-04-30T20:55:51.830154+00:00 [running]> on host f153e58ecd1c
[2024-05-01T18:49:20.070+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='homework2_data_pipeline_demo' AIRFLOW_CTX_TASK_ID='data_acquisition' AIRFLOW_CTX_EXECUTION_DATE='2024-04-30T20:55:51.830154+00:00' AIRFLOW_CTX_TRY_NUMBER='17' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-04-30T20:55:51.830154+00:00'
[2024-05-01T18:49:20.074+0000] {process_utils.py:182} INFO - Executing cmd: /usr/local/bin/python -m virtualenv /tmp/venv762bqnpi --python=python
[2024-05-01T18:49:20.087+0000] {process_utils.py:186} INFO - Output:
[2024-05-01T18:49:21.168+0000] {process_utils.py:190} INFO - created virtual environment CPython3.8.19.final.0-64 in 421ms
[2024-05-01T18:49:21.169+0000] {process_utils.py:190} INFO -   creator CPython3Posix(dest=/tmp/venv762bqnpi, clear=False, no_vcs_ignore=False, global=False)
[2024-05-01T18:49:21.170+0000] {process_utils.py:190} INFO -   seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/home/***/.local/share/virtualenv)
[2024-05-01T18:49:21.171+0000] {process_utils.py:190} INFO -     added seed packages: pip==24.0, setuptools==69.2.0, wheel==0.43.0
[2024-05-01T18:49:21.171+0000] {process_utils.py:190} INFO -   activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator
[2024-05-01T18:49:21.215+0000] {process_utils.py:182} INFO - Executing cmd: /tmp/venv762bqnpi/bin/pip install -r /tmp/venv762bqnpi/requirements.txt
[2024-05-01T18:49:21.227+0000] {process_utils.py:186} INFO - Output:
[2024-05-01T18:49:22.895+0000] {process_utils.py:190} INFO - Collecting dill (from -r /tmp/venv762bqnpi/requirements.txt (line 1))
[2024-05-01T18:49:22.898+0000] {process_utils.py:190} INFO -   Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)
[2024-05-01T18:49:22.932+0000] {process_utils.py:190} INFO - Collecting funcsigs (from -r /tmp/venv762bqnpi/requirements.txt (line 2))
[2024-05-01T18:49:22.935+0000] {process_utils.py:190} INFO -   Using cached funcsigs-1.0.2-py2.py3-none-any.whl.metadata (14 kB)
[2024-05-01T18:49:23.303+0000] {process_utils.py:190} INFO - Collecting pandas (from -r /tmp/venv762bqnpi/requirements.txt (line 3))
[2024-05-01T18:49:23.306+0000] {process_utils.py:190} INFO -   Using cached pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)
[2024-05-01T18:49:23.516+0000] {process_utils.py:190} INFO - Collecting python-dateutil>=2.8.2 (from pandas->-r /tmp/venv762bqnpi/requirements.txt (line 3))
[2024-05-01T18:49:23.519+0000] {process_utils.py:190} INFO -   Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)
[2024-05-01T18:49:23.655+0000] {process_utils.py:190} INFO - Collecting pytz>=2020.1 (from pandas->-r /tmp/venv762bqnpi/requirements.txt (line 3))
[2024-05-01T18:49:23.658+0000] {process_utils.py:190} INFO -   Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)
[2024-05-01T18:49:23.708+0000] {process_utils.py:190} INFO - Collecting tzdata>=2022.1 (from pandas->-r /tmp/venv762bqnpi/requirements.txt (line 3))
[2024-05-01T18:49:23.712+0000] {process_utils.py:190} INFO -   Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)
[2024-05-01T18:49:24.189+0000] {process_utils.py:190} INFO - Collecting numpy>=1.20.3 (from pandas->-r /tmp/venv762bqnpi/requirements.txt (line 3))
[2024-05-01T18:49:24.192+0000] {process_utils.py:190} INFO -   Using cached numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)
[2024-05-01T18:49:24.245+0000] {process_utils.py:190} INFO - Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas->-r /tmp/venv762bqnpi/requirements.txt (line 3))
[2024-05-01T18:49:24.248+0000] {process_utils.py:190} INFO -   Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)
[2024-05-01T18:49:24.267+0000] {process_utils.py:190} INFO - Using cached dill-0.3.8-py3-none-any.whl (116 kB)
[2024-05-01T18:49:24.271+0000] {process_utils.py:190} INFO - Using cached funcsigs-1.0.2-py2.py3-none-any.whl (17 kB)
[2024-05-01T18:49:24.274+0000] {process_utils.py:190} INFO - Using cached pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)
[2024-05-01T18:49:24.342+0000] {process_utils.py:190} INFO - Using cached numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)
[2024-05-01T18:49:24.434+0000] {process_utils.py:190} INFO - Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)
[2024-05-01T18:49:24.438+0000] {process_utils.py:190} INFO - Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)
[2024-05-01T18:49:24.444+0000] {process_utils.py:190} INFO - Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)
[2024-05-01T18:49:24.449+0000] {process_utils.py:190} INFO - Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)
[2024-05-01T18:49:24.911+0000] {process_utils.py:190} INFO - Installing collected packages: pytz, funcsigs, tzdata, six, numpy, dill, python-dateutil, pandas
[2024-05-01T18:49:34.631+0000] {process_utils.py:190} INFO - Successfully installed dill-0.3.8 funcsigs-1.0.2 numpy-1.24.4 pandas-2.0.3 python-dateutil-2.9.0.post0 pytz-2024.1 six-1.16.0 tzdata-2024.1
[2024-05-01T18:49:35.097+0000] {process_utils.py:182} INFO - Executing cmd: /tmp/venv762bqnpi/bin/python /tmp/venv-callluelrzee/script.py /tmp/venv-callluelrzee/script.in /tmp/venv-callluelrzee/script.out /tmp/venv-callluelrzee/string_args.txt /tmp/venv-callluelrzee/termination.log
[2024-05-01T18:49:35.108+0000] {process_utils.py:186} INFO - Output:
[2024-05-01T18:49:35.715+0000] {process_utils.py:190} INFO - Traceback (most recent call last):
[2024-05-01T18:49:35.716+0000] {process_utils.py:190} INFO -   File "/tmp/venv-callluelrzee/script.py", line 69, in <module>
[2024-05-01T18:49:35.716+0000] {process_utils.py:190} INFO -     res = data_acquisition(*arg_dict["args"], **arg_dict["kwargs"])
[2024-05-01T18:49:35.717+0000] {process_utils.py:190} INFO -   File "/tmp/venv-callluelrzee/script.py", line 38, in data_acquisition
[2024-05-01T18:49:35.717+0000] {process_utils.py:190} INFO -     df.to_csv(data_path, index=False)
[2024-05-01T18:49:35.718+0000] {process_utils.py:190} INFO -   File "/tmp/venv762bqnpi/lib/python3.8/site-packages/pandas/core/generic.py", line 3772, in to_csv
[2024-05-01T18:49:35.719+0000] {process_utils.py:190} INFO -     return DataFrameRenderer(formatter).to_csv(
[2024-05-01T18:49:35.720+0000] {process_utils.py:190} INFO -   File "/tmp/venv762bqnpi/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1186, in to_csv
[2024-05-01T18:49:35.720+0000] {process_utils.py:190} INFO -     csv_formatter.save()
[2024-05-01T18:49:35.721+0000] {process_utils.py:190} INFO -   File "/tmp/venv762bqnpi/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 240, in save
[2024-05-01T18:49:35.722+0000] {process_utils.py:190} INFO -     with get_handle(
[2024-05-01T18:49:35.723+0000] {process_utils.py:190} INFO -   File "/tmp/venv762bqnpi/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
[2024-05-01T18:49:35.724+0000] {process_utils.py:190} INFO -     handle = open(
[2024-05-01T18:49:35.725+0000] {process_utils.py:190} INFO - IsADirectoryError: [Errno 21] Is a directory: '/storage/acquire/'
[2024-05-01T18:49:36.157+0000] {taskinstance.py:2731} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 444, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 414, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/decorators/base.py", line 241, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 401, in execute
    return super().execute(context=serializable_context)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 200, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 723, in execute_callable
    result = self._execute_python_callable_in_subprocess(python_path)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 478, in _execute_python_callable_in_subprocess
    raise AirflowException(error_msg) from None
airflow.exceptions.AirflowException: Process returned non-zero exit status 1.
[Errno 21] Is a directory: '/storage/acquire/'
[2024-05-01T18:49:36.163+0000] {taskinstance.py:1149} INFO - Marking task as FAILED. dag_id=homework2_data_pipeline_demo, task_id=data_acquisition, execution_date=20240430T205551, start_date=20240501T184919, end_date=20240501T184936
[2024-05-01T18:49:36.185+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 136 for task data_acquisition (Process returned non-zero exit status 1.
[Errno 21] Is a directory: '/storage/acquire/'; 10193)
[2024-05-01T18:49:36.199+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2024-05-01T18:49:36.235+0000] {taskinstance.py:3312} INFO - 0 downstream tasks scheduled from follow-on schedule check
